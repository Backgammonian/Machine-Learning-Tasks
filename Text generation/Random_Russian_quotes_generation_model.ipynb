{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "KYQGyj3VyaCc",
      "metadata": {
        "id": "KYQGyj3VyaCc"
      },
      "source": [
        "Mostly based on this notebook: https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_10_3_text_generation.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ced7269",
      "metadata": {
        "id": "6ced7269"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "nJOmx15llSrY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJOmx15llSrY",
        "outputId": "2bbae3ed-e272-4e17-a6f3-63b4bccc4dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "drive_path = 'drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9e2dced3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T10:13:05.166569Z",
          "start_time": "2023-12-04T10:13:05.156570Z"
        },
        "id": "9e2dced3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 50)\n",
        "pd.set_option('display.max_columns', 10)\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "234b9fbe",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T10:08:53.516534Z",
          "start_time": "2023-12-04T10:08:45.312621Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "234b9fbe",
        "outputId": "88162f65-a47d-4b2d-a60d-6090c424ef59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.callbacks import LambdaCallback\n",
        "\n",
        "# List of devices\n",
        "tf.config.list_physical_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2778f912",
      "metadata": {
        "id": "2778f912"
      },
      "source": [
        "# Open quotes text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ac2f5eb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac2f5eb0",
        "outputId": "e8a70954-3041-43aa-e665-1bdebc2edaf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines count in the quotes file: 67086\n",
            "Lines count in the shorter version of file: 11181\n"
          ]
        }
      ],
      "source": [
        "f = open(f'{drive_path}/quotes.txt', 'r', encoding = 'utf-8')\n",
        "lines = f.readlines()\n",
        "lines_count = len(lines)\n",
        "f.close()\n",
        "new_lines_count = lines_count // 6\n",
        "\n",
        "print(f'Lines count in the quotes file: {lines_count}')\n",
        "print(f'Lines count in the shorter version of file: {new_lines_count}')\n",
        "\n",
        "f = open(f'{drive_path}/quotes.txt', 'r', encoding = 'utf-8')\n",
        "g = open(f'{drive_path}/quotes_one_sixth_version.txt', 'w', encoding = 'utf-8')\n",
        "for i in range(0, new_lines_count):\n",
        "    line = f.readline()\n",
        "    g.write(line)\n",
        "f.close()\n",
        "g.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7bb73224",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T10:15:52.027283Z",
          "start_time": "2023-12-04T10:15:51.862283Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bb73224",
        "outputId": "9eef4784-4a1e-43fb-f902-82bf46c90aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quotes count: 11181\n"
          ]
        }
      ],
      "source": [
        "# file_path = f'{drive_path}/quotes.txt'\n",
        "file_path = f'{drive_path}/quotes_one_sixth_version.txt'\n",
        "f = open(file_path, 'r', encoding = 'utf-8')\n",
        "quotes = f.readlines()\n",
        "f.close()\n",
        "\n",
        "print(f'Quotes count: {len(quotes)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6f55a9a5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T10:18:48.130820Z",
          "start_time": "2023-12-04T10:18:48.095820Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f55a9a5",
        "outputId": "d7beeada-0a8b-4a64-95c5-c83413144205"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw text length: 1671104\n"
          ]
        }
      ],
      "source": [
        "raw_text = ''.join(quotes)\n",
        "\n",
        "print(f'Raw text length: {len(raw_text)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f19d66",
      "metadata": {
        "id": "b6f19d66"
      },
      "source": [
        "# Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "52d633c7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T10:28:34.630360Z",
          "start_time": "2023-12-04T10:28:34.610307Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "52d633c7",
        "outputId": "0a927078-8287-4740-e382-a81f638baf7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'— Достаточно, — резко оборвала его Рейна. — Аннабет говорит правду. Она пришла с миром. Кроме того...— Рейна посмотрела на Аннабет с невольным уважением. — Перси высоко о тебе отзывался. Подтекст в голосе Рейны занял у Аннабет мгновение, чтобы понять его. Взгляд Перси был устремлен вниз, внезапно заинтересовавшись лежащим на тарелке чизбургером. Лицо Аннабет запылало. О, Боги... Рейна пыталась сблизиться с Перси. Это объясняло оттенок горечи, возможно даже зависти в её словах. Перси предпочел ей Аннабет. В тот момент, Аннабет простила своему нелепому парню все, что он когда-либо делал неправильно. Она хотела обнять его, но приказала себе оставаться спокойной.\\nРоссия стоит между Азией и Европой. Мы вам сделали теплицу. Вы в теплице. Согреваетесь под теплым солнышком, потому что на ваши головы не падают бомбы. Потому что на Востоке стоит русская армия!\\nМы убьем его добротой, но только вместо доброты используем оружие.\\nДамы, не худейте. Оно вам надо? Уж лучше к старости быть р'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "raw_text[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7728f5a0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T10:29:50.412132Z",
          "start_time": "2023-12-04T10:29:49.472064Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7728f5a0",
        "outputId": "d92c8c5c-e735-41b2-e34b-3d789a3b8d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus length: 1671104\n",
            "Total chars: 135\n"
          ]
        }
      ],
      "source": [
        "processed_text = raw_text.lower()\n",
        "# processed_text = re.sub(r'[^\\x00-\\x7f]', r'', processed_text)\n",
        "chars = sorted(list(set(processed_text)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print(f'Corpus length: {len(processed_text)}')\n",
        "print(f'Total chars: {len(chars)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d48d9239",
      "metadata": {
        "id": "d48d9239"
      },
      "source": [
        "# Build the sentence sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "783d2925",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T10:30:19.609294Z",
          "start_time": "2023-12-04T10:30:16.334629Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "783d2925",
        "outputId": "2f0be580-d9d8-444d-a63d-ccf397b4342f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequences: 167106\n"
          ]
        }
      ],
      "source": [
        "maxlen = 50\n",
        "step = 10\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(processed_text) - maxlen, step):\n",
        "    sentences.append(processed_text[i: i + maxlen])\n",
        "    next_chars.append(processed_text[i + maxlen])\n",
        "\n",
        "print(f'Number of sequences: {len(sentences)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b1097003",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T10:30:34.800924Z",
          "start_time": "2023-12-04T10:30:34.780858Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1097003",
        "outputId": "c21c732a-6ef1-41cb-c928-8bdfc1869d4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['— достаточно, — резко оборвала его рейна. — аннаб',\n",
              " 'но, — резко оборвала его рейна. — аннабет говорит',\n",
              " 'о оборвала его рейна. — аннабет говорит правду. о',\n",
              " ' его рейна. — аннабет говорит правду. она пришла ',\n",
              " 'а. — аннабет говорит правду. она пришла с миром. к',\n",
              " 'ет говорит правду. она пришла с миром. кроме того.',\n",
              " ' правду. она пришла с миром. кроме того...— рейна',\n",
              " 'на пришла с миром. кроме того...— рейна посмотрел',\n",
              " 'с миром. кроме того...— рейна посмотрела на аннаб',\n",
              " 'роме того...— рейна посмотрела на аннабет с невол',\n",
              " '..— рейна посмотрела на аннабет с невольным уваже',\n",
              " ' посмотрела на аннабет с невольным уважением. — пе',\n",
              " 'а на аннабет с невольным уважением. — перси высоко',\n",
              " 'ет с невольным уважением. — перси высоко о тебе от',\n",
              " 'ьным уважением. — перси высоко о тебе отзывался. п',\n",
              " 'нием. — перси высоко о тебе отзывался. подтекст в ',\n",
              " 'рси высоко о тебе отзывался. подтекст в голосе реи',\n",
              " ' о тебе отзывался. подтекст в голосе рейны занял ',\n",
              " 'зывался. подтекст в голосе рейны занял у аннабет ',\n",
              " 'одтекст в голосе рейны занял у аннабет мгновение,']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "sentences[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e620b6ad",
      "metadata": {
        "id": "e620b6ad"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bebe3839",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T10:55:02.098887Z",
          "start_time": "2023-12-04T10:52:47.771340Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bebe3839",
        "outputId": "3c4eb503-33bf-4440-cbc8-00d5c2d728ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-c3dbc2329c7d>:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool)\n",
            "<ipython-input-12-c3dbc2329c7d>:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(chars)), dtype = np.bool)\n"
          ]
        }
      ],
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype = np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype = np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dada321",
      "metadata": {
        "id": "4dada321"
      },
      "source": [
        "# Create LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "58357926",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T11:14:45.821161Z",
          "start_time": "2023-12-04T11:14:40.657464Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58357926",
        "outputId": "de57488a-7432-464e-e208-afe47e5e0ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               135168    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 135)               17415     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 152583 (596.03 KB)\n",
            "Trainable params: 152583 (596.03 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    LSTM(128, input_shape = (maxlen, len(chars))),\n",
        "    # LSTM(64, input_shape = (maxlen, len(chars)), return_sequences = True),\n",
        "    # LSTM(32),\n",
        "    Dense(len(chars), activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4089b309",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T11:16:42.043016Z",
          "start_time": "2023-12-04T11:16:42.033013Z"
        },
        "id": "4089b309"
      },
      "outputs": [],
      "source": [
        "# Helper function to sample an index from a probability array\n",
        "def sample(preds, temperature = 1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "# Function invoked at end of each epoch. Prints generated text.\n",
        "def on_epoch_end(epoch, _):\n",
        "    if (epoch + 1) % 10 != 0:\n",
        "        return\n",
        "    print('*' * 10)\n",
        "    print(f'*** Generating text after epoch #{epoch + 1}')\n",
        "    start_index = random.randint(0, len(processed_text) - maxlen - 1)\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print(f'* Temperature: {temperature}')\n",
        "        generated = ''\n",
        "        sentence = processed_text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print(f'* Generating with seed: \"{sentence}\"')\n",
        "        sys.stdout.write(generated)\n",
        "        for i in range(200):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.0\n",
        "            # preds = model.predict(x_pred, verbose = 0)[0]\n",
        "            preds = model.predict_on_batch(x_pred)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = indices_char[next_index]\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8aef8480",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T11:21:30.063496Z",
          "start_time": "2023-12-04T11:21:19.582173Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aef8480",
        "outputId": "6d33e47d-55a4-425c-b0c4-08ab2b12a18a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1306/1306 [==============================] - 14s 6ms/step - loss: 2.8322\n",
            "Epoch 2/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 2.4445\n",
            "Epoch 3/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 2.3319\n",
            "Epoch 4/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 2.2541\n",
            "Epoch 5/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 2.1841\n",
            "Epoch 6/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 2.1211\n",
            "Epoch 7/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 2.0702\n",
            "Epoch 8/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 2.0265\n",
            "Epoch 9/100\n",
            "1306/1306 [==============================] - 11s 8ms/step - loss: 1.9877\n",
            "Epoch 10/100\n",
            "1304/1306 [============================>.] - ETA: 0s - loss: 1.9536**********\n",
            "*** Generating text after epoch #10\n",
            "* Temperature: 0.2\n",
            "* Generating with seed: \" вид одиночества. успех принёс мне всемирное покл\"\n",
            " вид одиночества. успех принёс мне всемирное покледные странить не всегда своих своих дела тебя в дела в своих дела в своим всегда свои просто всегда всегда всегда всегда приводить свой дела в свой жизнь всегда поделать в свой просто они привали \n",
            "* Temperature: 0.5\n",
            "* Generating with seed: \" вид одиночества. успех принёс мне всемирное покл\"\n",
            " вид одиночества. успех принёс мне всемирное покликающие любовь большо собой пристаться смерть всегда поку мы за дела в потому в тороду можно и приходная своиму не всегда свой тогда свое человека станить о и посодней сторовить подеть все дамого н\n",
            "* Temperature: 1.0\n",
            "* Generating with seed: \" вид одиночества. успех принёс мне всемирное покл\"\n",
            " вид одиночества. успех принёс мне всемирное покливего? забезансев корда, с моском от кареёльет в эмисм обстоюние.\n",
            "я другом моребутьяя жей.\n",
            "поподьются стается туплялней довь. я выщастельма в как по-имя вщевму.\n",
            "предоррге.  не нам чшит груда.\n",
            "несто\n",
            "* Temperature: 1.2\n",
            "* Generating with seed: \" вид одиночества. успех принёс мне всемирное покл\"\n",
            " вид одиночества. успех принёс мне всемирное покликвен7имный т преел пихой в маюд, умнутк.\n",
            "что свок, ноббляткиг пермы в сдех сободаячить явлю.\n",
            "провлют — и четочестоо, может нат.ча случатленуе скалых — да...., коse болеским ивечикик многли пляжи вс\n",
            "1306/1306 [==============================] - 17s 13ms/step - loss: 1.9535\n",
            "Epoch 11/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.9227\n",
            "Epoch 12/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.8937\n",
            "Epoch 13/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.8669\n",
            "Epoch 14/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.8438\n",
            "Epoch 15/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.8235\n",
            "Epoch 16/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.8020\n",
            "Epoch 17/100\n",
            "1306/1306 [==============================] - 10s 7ms/step - loss: 1.7833\n",
            "Epoch 18/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.7660\n",
            "Epoch 19/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.7497\n",
            "Epoch 20/100\n",
            "1300/1306 [============================>.] - ETA: 0s - loss: 1.7340**********\n",
            "*** Generating text after epoch #20\n",
            "* Temperature: 0.2\n",
            "* Generating with seed: \" плохие любовники! им не нужно напрягаться!\n",
            "всё в\"\n",
            " плохие любовники! им не нужно напрягаться!\n",
            "всё время в нем не станить постоянный сердце и тогда не странеть не принять в своих приводит не принет в не забедет в не всегда все самом вереть странной себя с нем не подобрать не странной сердце не пр\n",
            "* Temperature: 0.5\n",
            "* Generating with seed: \" плохие любовники! им не нужно напрягаться!\n",
            "всё в\"\n",
            " плохие любовники! им не нужно напрягаться!\n",
            "всё всегда их не походя рассказать.\n",
            "они есть что ее отонет.\n",
            "если понимать с возводит мир все возможность не подямая ребе не после прибода страхом совранием не поросинного умеешь с меня на привывается за те\n",
            "* Temperature: 1.0\n",
            "* Generating with seed: \" плохие любовники! им не нужно напрягаться!\n",
            "всё в\"\n",
            " плохие любовники! им не нужно напрягаться!\n",
            "всё ворвняющей. деторкии фишьмиранов инрерот прифетруми не к не их на се же, сталение к помочить любить хватесно не самоевшей тольбы вы предвпроровики идет дву, и не твоите сбобоцы. чем не убити, чтобя с\n",
            "* Temperature: 1.2\n",
            "* Generating with seed: \" плохие любовники! им не нужно напрягаться!\n",
            "всё в\"\n",
            " плохие любовники! им не нужно напрягаться!\n",
            "всё возроссопиноески раз для не звезда-то времяны! боякис — ты быт не неознеднами могудте всяр сещей люде, концо, – лучаско дeфеости, стожерный длюжит тальноку, но очпоженнее горднуе, приподують; и думае\n",
            "1306/1306 [==============================] - 16s 12ms/step - loss: 1.7337\n",
            "Epoch 21/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.7200\n",
            "Epoch 22/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.7074\n",
            "Epoch 23/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.6939\n",
            "Epoch 24/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.6820\n",
            "Epoch 25/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.6702\n",
            "Epoch 26/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.6595\n",
            "Epoch 27/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.6488\n",
            "Epoch 28/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.6386\n",
            "Epoch 29/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.6289\n",
            "Epoch 30/100\n",
            "1302/1306 [============================>.] - ETA: 0s - loss: 1.6199**********\n",
            "*** Generating text after epoch #30\n",
            "* Temperature: 0.2\n",
            "* Generating with seed: \"бовь к родителям — основа всех добродетелей.\n",
            "жить\"\n",
            "бовь к родителям — основа всех добродетелей.\n",
            "жить в не может быть в том, что он не полока, а если ты не старение — это не получать все образуть свой своих думаешь и своим старая собственно не понимаю жизнь — это только ты не могу человека на старат\n",
            "* Temperature: 0.5\n",
            "* Generating with seed: \"бовь к родителям — основа всех добродетелей.\n",
            "жить\"\n",
            "бовь к родителям — основа всех добродетелей.\n",
            "жить было ты нас нашу ведительно уже не лечения делать так польке ответоми, а не зависаться положить их увериты. на сильно. надежду и теплое — они правда свой своих и всегда истории представляется на хоч\n",
            "* Temperature: 1.0\n",
            "* Generating with seed: \"бовь к родителям — основа всех добродетелей.\n",
            "жить\"\n",
            "бовь к родителям — основа всех добродетелей.\n",
            "жить я готомы и нежерь! и в нем.\n",
            "были он надсегда вольше впесох.\n",
            "этой сил нишей ф нирити меняе второй — то, как и прозову. когда мы кто не пустыми мы калит, как уюд, смиршть отвечалось затом чужите, а \n",
            "* Temperature: 1.2\n",
            "* Generating with seed: \"бовь к родителям — основа всех добродетелей.\n",
            "жить\"\n",
            "бовь к родителям — основа всех добродетелей.\n",
            "жить. сирал всё кто-нипуды моего нами. но гак у чше людей того, да нижеть, иногда-то тебя женся. не мочка, мы навойца ин, и не бозадешь не положь камсян? шоб стая эобыдь добеге, услекогой, дитудря сто\n",
            "1306/1306 [==============================] - 16s 12ms/step - loss: 1.6196\n",
            "Epoch 31/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.6117\n",
            "Epoch 32/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.6020\n",
            "Epoch 33/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.5947\n",
            "Epoch 34/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5860\n",
            "Epoch 35/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5783\n",
            "Epoch 36/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5784\n",
            "Epoch 37/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5643\n",
            "Epoch 38/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5574\n",
            "Epoch 39/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5500\n",
            "Epoch 40/100\n",
            "1306/1306 [==============================] - ETA: 0s - loss: 1.5437**********\n",
            "*** Generating text after epoch #40\n",
            "* Temperature: 0.2\n",
            "* Generating with seed: \"и? было ли случившееся бесспорным чудом или не был\"\n",
            "и? было ли случившееся бесспорным чудом или не было тем не могут большенные делать своих думаю, что такое совершение на своих делать своих деньги — это не знает, что такое страданий в неть в сердце не просто не старение с томой на своих деньги дела\n",
            "* Temperature: 0.5\n",
            "* Generating with seed: \"и? было ли случившееся бесспорным чудом или не был\"\n",
            "и? было ли случившееся бесспорным чудом или не был даже совершает подпревлагие.\n",
            "— даление странь.\n",
            "я не верённый человек бестанение и самое не привыланного слушать враг и нет. они полонить возможность, чтобы сердца и доброй положения реши. они все \n",
            "* Temperature: 1.0\n",
            "* Generating with seed: \"и? было ли случившееся бесспорным чудом или не был\"\n",
            "и? было ли случившееся бесспорным чудом или не был мечта, усневать восному «даржизовил: мое — это меняешь, как дале и поздное представляются на курти концебе, но только долгу, хоромы какоры. хогно и челодейстривилусь работте, что в неимоющим и подяя\n",
            "* Temperature: 1.2\n",
            "* Generating with seed: \"и? было ли случившееся бесспорным чудом или не был\"\n",
            "и? было ли случившееся бесспорным чудом или не былу. зазьедаешь ражать или, тоберан: и кончивая совершанполикая, когда чувство истрено обедразного голоза пенорут, эниить гор, и должин там значия севья, болушно какие устрии.\n",
            "наротиворевно!\n",
            "“сохой, ко\n",
            "1306/1306 [==============================] - 16s 12ms/step - loss: 1.5437\n",
            "Epoch 41/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5378\n",
            "Epoch 42/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5326\n",
            "Epoch 43/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.5249\n",
            "Epoch 44/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5186\n",
            "Epoch 45/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5133\n",
            "Epoch 46/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5065\n",
            "Epoch 47/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.5021\n",
            "Epoch 48/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4959\n",
            "Epoch 49/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4899\n",
            "Epoch 50/100\n",
            "1306/1306 [==============================] - ETA: 0s - loss: 1.4851**********\n",
            "*** Generating text after epoch #50\n",
            "* Temperature: 0.2\n",
            "* Generating with seed: \" капелек росы и солнечных лучиков, — сеть из мысле\"\n",
            " капелек росы и солнечных лучиков, — сеть из мыслей возрастрал на своих дома — то нет просто своей женщины и всегда может быть стараться свои от бывает состоянно поддерет в общество и всегда принодение на свой в глаза и всегда дома слова и всегда \n",
            "* Temperature: 0.5\n",
            "* Generating with seed: \" капелек росы и солнечных лучиков, — сеть из мысле\"\n",
            " капелек росы и солнечных лучиков, — сеть из мыслей, которые его свобода бы так не ведить всегда может довольно на такое такое самые пусто не обытадял мой проблема — от тебя образу подерном так и самые великах в обываются нам не меня, которые он сл\n",
            "* Temperature: 1.0\n",
            "* Generating with seed: \" капелек росы и солнечных лучиков, — сеть из мысле\"\n",
            " капелек росы и солнечных лучиков, — сеть из мыслечивается самые вещину истинная то, что такой.\n",
            "для не в не тоблю своим светы может бога то ушарственных и заимственного мили нужа. моя писаешься. <...> что-то достоканща вот зло, нечегд. и любве, заро\n",
            "* Temperature: 1.2\n",
            "* Generating with seed: \" капелек росы и солнечных лучиков, — сеть из мысле\"\n",
            " капелек росы и солнечных лучиков, — сеть из мыслели не заплодий.\n",
            "... летиче его слишко, и толзы, я вазбо, не осчитания успомил один беспокминываются» «ставда — боть жиборижие не значит.\n",
            "дни идию за мал «я оброжать правды, я сбажают мир нувеште?» не\n",
            "1306/1306 [==============================] - 16s 12ms/step - loss: 1.4851\n",
            "Epoch 51/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4793\n",
            "Epoch 52/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4743\n",
            "Epoch 53/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.4691\n",
            "Epoch 54/100\n",
            "1306/1306 [==============================] - 10s 8ms/step - loss: 1.4641\n",
            "Epoch 55/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4583\n",
            "Epoch 56/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4535\n",
            "Epoch 57/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4478\n",
            "Epoch 58/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4437\n",
            "Epoch 59/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4393\n",
            "Epoch 60/100\n",
            "1303/1306 [============================>.] - ETA: 0s - loss: 1.4336**********\n",
            "*** Generating text after epoch #60\n",
            "* Temperature: 0.2\n",
            "* Generating with seed: \"! — можно было, если бы ты не включила свет и не в\"\n",
            "! — можно было, если бы ты не включила свет и не все бывает возвращается в жизнь — это себя на все долго должны предстанеть свои просто не может быть в сердце и всё удрании и тогда делает в могу выбор и нет себя у тебя поддразный себя становится в \n",
            "* Temperature: 0.5\n",
            "* Generating with seed: \"! — можно было, если бы ты не включила свет и не в\"\n",
            "! — можно было, если бы ты не включила свет и не все было выбора — это не знаешь, что вериться на тебе не становится в жизнь все равно было умерить весно, что на пользля так, что он выбера и не было на страхом в себе всё удивая семьи делать себя, и \n",
            "* Temperature: 1.0\n",
            "* Generating with seed: \"! — можно было, если бы ты не включила свет и не в\"\n",
            "! — можно было, если бы ты не включила свет и не вся. не сдалое, пустаншие просто, и ты этот сождать на тебя как при лисшье мне одавих глупке.\n",
            "изамил остаться.\n",
            "ну «выглюбий в для ремор по-другой можно простусался до светрезных руку — в беспостует т\n",
            "* Temperature: 1.2\n",
            "* Generating with seed: \"! — можно было, если бы ты не включила свет и не в\"\n",
            "! — можно было, если бы ты не включила свет и не верят крые этих говорит, потому что застядляя цуждама, что вы и ещё пректнитку это стоит мхати.\n",
            "имекния человек ты подоб заблимии себе жизнь. не в том...\n",
            "рабоваться помывшие праву усуществием». мечца \n",
            "1306/1306 [==============================] - 16s 12ms/step - loss: 1.4336\n",
            "Epoch 61/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4292\n",
            "Epoch 62/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4240\n",
            "Epoch 63/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.4201\n",
            "Epoch 64/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4151\n",
            "Epoch 65/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4174\n",
            "Epoch 66/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4077\n",
            "Epoch 67/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.4023\n",
            "Epoch 68/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3990\n",
            "Epoch 69/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3937\n",
            "Epoch 70/100\n",
            "1303/1306 [============================>.] - ETA: 0s - loss: 1.3930**********\n",
            "*** Generating text after epoch #70\n",
            "* Temperature: 0.2\n",
            "* Generating with seed: \"е, спасённые люди — ими вы оправдываете свои жалк\"\n",
            "е, спасённые люди — ими вы оправдываете свои жалки по суддать и себя.\n",
            "если я не знает, что подаёт в ней только ты по своим становится на тебе не принцивает себя приводит в пости нет проблема с только просто нас тебе не существует. и всегда станет \n",
            "* Temperature: 0.5\n",
            "* Generating with seed: \"е, спасённые люди — ими вы оправдываете свои жалк\"\n",
            "е, спасённые люди — ими вы оправдываете свои жалки просто невередерен, поэтому чтобы есть своих слабым проблема с нед воспоким становешь себя ополосте насторое прирав лег тебя понимания. мне месте не просто необновишься сама не природе все в жизни, \n",
            "* Temperature: 1.0\n",
            "* Generating with seed: \"е, спасённые люди — ими вы оправдываете свои жалк\"\n",
            "е, спасённые люди — ими вы оправдываете свои жалки созновал или, а ещё угбота — или забыть бойсат даже ево своего предине людей, сейчас в нем он, на положения во отноше — нужно, мне представляет невазин, мужчина безвысвает по проблез, которые ли\n",
            "* Temperature: 1.2\n",
            "* Generating with seed: \"е, спасённые люди — ими вы оправдываете свои жалк\"\n",
            "е, спасённые люди — ими вы оправдываете свои жалки, других поступки.\n",
            "прежду боюзнь поддыва прокродеть неге навишешь кто-то, скозность эгадание?\n",
            "дае. твой, пока то, что може» имоегда с людей руки, слимих лучно хотят зданые пестершиваем. тех, кто пи\n",
            "1306/1306 [==============================] - 16s 12ms/step - loss: 1.3930\n",
            "Epoch 71/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3926\n",
            "Epoch 72/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3827\n",
            "Epoch 73/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.3788\n",
            "Epoch 74/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3878\n",
            "Epoch 75/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3811\n",
            "Epoch 76/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3713\n",
            "Epoch 77/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3691\n",
            "Epoch 78/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3639\n",
            "Epoch 79/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3609\n",
            "Epoch 80/100\n",
            "1302/1306 [============================>.] - ETA: 0s - loss: 1.3580**********\n",
            "*** Generating text after epoch #80\n",
            "* Temperature: 0.2\n",
            "* Generating with seed: \"ж в спину ближнему.\n",
            "нет ничего тягостней мучитель\"\n",
            "ж в спину ближнему.\n",
            "нет ничего тягостней мучительно подобла родителей возможность в ней если не надо подолодные меня и возможность в ней если не понимаешь, что он страшно, но не с керено подолчановиться на тогда может быть старшение подоблая свои\n",
            "* Temperature: 0.5\n",
            "* Generating with seed: \"ж в спину ближнему.\n",
            "нет ничего тягостней мучитель\"\n",
            "ж в спину ближнему.\n",
            "нет ничего тягостней мучительно и тогда дето, что тебе не проплое возможность.\n",
            "если ты не прицер к спровила и другими подобна большо полна своей само прошломы, который из неиные оттогу поддумалов подобно реальности. в прикажул \n",
            "* Temperature: 1.0\n",
            "* Generating with seed: \"ж в спину ближнему.\n",
            "нет ничего тягостней мучитель\"\n",
            "ж в спину ближнему.\n",
            "нет ничего тягостней мучительно, оно менят, когда выбудет костывает горезиматься когда-нибудь мороль, я сепдать». свою увидит? — это нём примещеской спотядью. подоблая шух, бессмысши, но ничего нет...\n",
            "расспобником знаюсь, что п\n",
            "* Temperature: 1.2\n",
            "* Generating with seed: \"ж в спину ближнему.\n",
            "нет ничего тягостней мучитель\"\n",
            "ж в спину ближнему.\n",
            "нет ничего тягостней мучитель, что согондя живать зо, к чувствуесь свити, не вынашент к исполон.\n",
            "обя огибою, мы, ино лыши, башье свои том, искосельны попередна не удациеской пасти, когда все свисит зло!\n",
            "есть токио прошлого сходи\n",
            "1306/1306 [==============================] - 16s 12ms/step - loss: 1.3579\n",
            "Epoch 81/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3539\n",
            "Epoch 82/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3480\n",
            "Epoch 83/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3516\n",
            "Epoch 84/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3479\n",
            "Epoch 85/100\n",
            "1306/1306 [==============================] - 8s 7ms/step - loss: 1.3391\n",
            "Epoch 86/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3448\n",
            "Epoch 87/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3375\n",
            "Epoch 88/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3295\n",
            "Epoch 89/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3275\n",
            "Epoch 90/100\n",
            "1304/1306 [============================>.] - ETA: 0s - loss: 1.3248**********\n",
            "*** Generating text after epoch #90\n",
            "* Temperature: 0.2\n",
            "* Generating with seed: \"ы увидишь как они вырастут. ты умрешь старой, ста\"\n",
            "ы увидишь как они вырастут. ты умрешь старой, становится в обычно собственной друг бо "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-b39c49399580>:4: RuntimeWarning: divide by zero encountered in log\n",
            "  preds = np.log(preds) / temperature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "старить не понимаешь, что во все один которых полна в ради тебе не было.\n",
            "ли чем на свои первые слово остаться в ней только ты не пониматься в навстал из вот в св\n",
            "* Temperature: 0.5\n",
            "* Generating with seed: \"ы увидишь как они вырастут. ты умрешь старой, ста\"\n",
            "ы увидишь как они вырастут. ты умрешь старой, становится ужи не застранной постояние — всторить, в этью края делавляется в ней всторение. я до совсем на краямного ребительное слова и чем смерти и всегда до только по прирасскаясь человеку, что може\n",
            "* Temperature: 1.0\n",
            "* Generating with seed: \"ы увидишь как они вырастут. ты умрешь старой, ста\"\n",
            "ы увидишь как они вырастут. ты умрешь старой, старости и лицом» — и есть вдий чаза — один что живёрью «миро согратиям. и разолокам силю больше нужно — это воспоминаний с сибых моей зуком, чтобы вот рабляговается сопредрамительности. когда умение\n",
            "* Temperature: 1.2\n",
            "* Generating with seed: \"ы увидишь как они вырастут. ты умрешь старой, ста\"\n",
            "ы увидишь как они вырастут. ты умрешь старой, сталя – это знаешь, что они умут.\n",
            "нет. нельзя: у мосчи и видим, почему не вехи. на ком-ний одиночество видем», фолько дригртык.\n",
            "что иногда кажето пехных и ты только плечатся так, что в сердце — особ.\n",
            "бо\n",
            "1306/1306 [==============================] - 16s 12ms/step - loss: 1.3248\n",
            "Epoch 91/100\n",
            "1306/1306 [==============================] - 10s 8ms/step - loss: 1.3210\n",
            "Epoch 92/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3266\n",
            "Epoch 93/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.3107\n",
            "Epoch 94/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3102\n",
            "Epoch 95/100\n",
            "1306/1306 [==============================] - 8s 6ms/step - loss: 1.3086\n",
            "Epoch 96/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3085\n",
            "Epoch 97/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3058\n",
            "Epoch 98/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3029\n",
            "Epoch 99/100\n",
            "1306/1306 [==============================] - 9s 7ms/step - loss: 1.3078\n",
            "Epoch 100/100\n",
            "1299/1306 [============================>.] - ETA: 0s - loss: 1.3009**********\n",
            "*** Generating text after epoch #100\n",
            "* Temperature: 0.2\n",
            "* Generating with seed: \"еко простирается твоя способность повелевать собои\"\n",
            "еко простирается твоя способность повелевать собой дома стой, как ты жизнь в любом мы созоваться в том, чтобы не природен. я не значит, что все возможно просто женщины — вы в чем от этот мир они было представляется такой страну и ничего не покрем \n",
            "* Temperature: 0.5\n",
            "* Generating with seed: \"еко простирается твоя способность повелевать собои\"\n",
            "еко простирается твоя способность повелевать собой.\n",
            " — нет того, как не только в горят, что не верит сказаться на своим притворили, когда вы встониться свободы и вот стой обычно стоит себе признанию об этими и сердце настоящее отецием слова в тайн\n",
            "* Temperature: 1.0\n",
            "* Generating with seed: \"еко простирается твоя способность повелевать собои\"\n",
            "еко простирается твоя способность повелевать собой? неналолшой: то, чео оставляет мек обреннеальну, что с собой дванстору, тот воюн карум, что сней он если под забот — ни гройно гредсоветсе спопидения. но игрыв мир тепелодостим.\n",
            "любом подтиние. \n",
            "* Temperature: 1.2\n",
            "* Generating with seed: \"еко простирается твоя способность повелевать собои\"\n",
            "еко простирается твоя способность повелевать собой. я жизнь (чё сколь, оне существов.\n",
            "богатно, который гополяться в здно, и зачивать закон пополовние догра, потому что это может послется жизнь грозатькрына; и впродоков! — запкоры, надо властьтя. ч\n",
            "1306/1306 [==============================] - 16s 12ms/step - loss: 1.3010\n"
          ]
        }
      ],
      "source": [
        "# Ignore useless W0819 warnings generated by TensorFlow 2.0. Hopefully can remove this ignore in the future.\n",
        "# See https://github.com/tensorflow/tensorflow/issues/31308\n",
        "import logging, os\n",
        "logging.disable(logging.WARNING)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end = on_epoch_end)\n",
        "history = model.fit(\n",
        "    x = x,\n",
        "    y = y,\n",
        "    callbacks = [print_callback],\n",
        "    batch_size = 128,\n",
        "    epochs = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2cfc95aa",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-04T11:15:17.333955Z",
          "start_time": "2023-12-04T11:15:14.123299Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "2cfc95aa",
        "outputId": "5d8680e4-45fb-416c-b928-d469d284f519"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "def show_training_history(history, metrics, metric_names, figure_size = (7, 6), last_epoch = None):\n",
        "    if len(metrics) == 1 and len(metric_names) == 1:\n",
        "        plt.figure(figsize = figure_size)\n",
        "        fig, ax = plt.subplots()\n",
        "        metric = metrics[0]\n",
        "        metric_name = metric_names[0]\n",
        "        ax.plot(history[metric], color = 'b', label = f'Training {metric_name}')\n",
        "        if f'val_{metric}' in history:\n",
        "            ax.plot(history[f'val_{metric}'], color = 'r', label = f'Validation {metric_name}')\n",
        "        if last_epoch is not None:\n",
        "            ax.axvline(x = last_epoch, color = 'g', label = 'Start of fine tuning')\n",
        "        legend = ax.legend(loc = 'best', shadow = True)\n",
        "        plt.show()\n",
        "    elif len(metrics) > 1 and len(metrics) == len(metric_names):\n",
        "        plt.figure(figsize = figure_size)\n",
        "        fig, ax = plt.subplots(len(metrics), 1)\n",
        "        for i in range(len(metrics)):\n",
        "            metric = metrics[i]\n",
        "            metric_name = metric_names[i]\n",
        "            ax[i].plot(history[metric], color = 'b', label = f'Training {metric_name}')\n",
        "            if f'val_{metric}' in history:\n",
        "                ax[i].plot(history[f'val_{metric}'], color = 'r', label = f'Validation {metric_name}', axes = ax[i])\n",
        "            if last_epoch is not None:\n",
        "                ax[i].axvline(x = last_epoch, color = 'g', label = 'Start of fine tuning')\n",
        "            legend = ax[i].legend(loc = 'best', shadow = True)\n",
        "        plt.show()\n",
        "    else:\n",
        "        raise Exception('Invalid metrics/metric names amount')\n",
        "\n",
        "show_training_history(\n",
        "    history.history,\n",
        "    ['loss'],\n",
        "    ['Loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CWqp_BeG72FA",
      "metadata": {
        "id": "CWqp_BeG72FA"
      },
      "source": [
        "# Test model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "16762901",
      "metadata": {
        "id": "16762901"
      },
      "outputs": [],
      "source": [
        "def test_model(model, input_sentence):\n",
        "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print(f'* Temperature: {temperature}')\n",
        "        generated = ''\n",
        "        generated += input_sentence\n",
        "        print(f'Generating with seed: \"{input_sentence}\"')\n",
        "        sentence = input_sentence\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.0\n",
        "            # preds = model.predict(x_pred, verbose = 0)[0]\n",
        "            preds = model.predict_on_batch(x_pred)[0]\n",
        "            next_index = sample(preds, temperature)\n",
        "            next_char = indices_char[next_index]\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "        print(f'Generated text: \"{generated}\"')\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83a9f05b",
      "metadata": {
        "id": "83a9f05b"
      },
      "source": [
        "## Using random input sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "771dd40a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "771dd40a",
        "outputId": "9f3aca15-5047-40ab-8a34-923a11956424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Temperature: 0.2\n",
            "Generating with seed: \" эта птица — орлан-белохвост. дерево в конце сада \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-b39c49399580>:4: RuntimeWarning: divide by zero encountered in log\n",
            "  preds = np.log(preds) / temperature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: \" эта птица — орлан-белохвост. дерево в конце сада подного представляется в жизни последний — сказать, что в рад последней того, что я не замечаться на кого-тор мы с того не завтра — одного не совершаем и принци и не пойтизм уже не может быть старьсые и ничего не привычка. но от тебе не существует себя стать собый просторовок — это собственной даже с темём на которой он стоиние становится на которых деними своих своей своей своей свобод \"\n",
            "\n",
            "* Temperature: 0.5\n",
            "Generating with seed: \" эта птица — орлан-белохвост. дерево в конце сада \"\n",
            "Generated text: \" эта птица — орлан-белохвост. дерево в конце сада не сделать так, что любовь с торого блаётся, что с той, позвыть, что я вообще всего другие просто нетраки!\n",
            "она не был «не забывается на плежденно, и тебе нак. я самому на причиние и история кажет на ком редерает всё порой проще достало и рассказать, что любом в главное, бесстоящему самоглязнью, но не спасений и слова, и подарась на свете своё не верит в одиночество слово с колнальных подлиже\"\n",
            "\n",
            "* Temperature: 1.0\n",
            "Generating with seed: \" эта птица — орлан-белохвост. дерево в конце сада \"\n",
            "Generated text: \" эта птица — орлан-белохвост. дерево в конце сада судьба! в одиночительный кранам значить, я силжания: ни однажды я ненависть, как узливают главноя. я глазах, которые доказаться в словами друзей, пряхождась бояться! это есть сказывает свек, чтобы каналось.\n",
            "утыся.\n",
            "человек улыбом, идести я воино не бесшает отвраститься с тобой — да разжают молез угодущее очивать деньго люди — это женщины как ниаке, что с ума — охотел, чтобы когда дело положить д\"\n",
            "\n",
            "* Temperature: 1.2\n",
            "Generating with seed: \" эта птица — орлан-белохвост. дерево в конце сада \"\n",
            "Generated text: \" эта птица — орлан-белохвост. дерево в конце сада — рюдив.\n",
            "это просыпают пормены.\n",
            "жем, мою знаемы огляилься. за нет. мы с вамох летает от вучили, скорокойствует.\n",
            "чего он безнасивы и гоэко чему слеза... это меня мы с деловах?\n",
            "гормою, мне людви». апрагивает блазуюли впереднее, смерться, — которох жена, правдаления я, ни ню фансевшисы. лоз бы цы к имуща, пожалоки, чтоб друх!\n",
            "эжиц исторокрасовалоской милого, выразание эте... потому жанти васного!\n",
            "е\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "start_index = random.randint(0, len(processed_text) - maxlen - 1)\n",
        "sentence = processed_text[start_index: start_index + maxlen]\n",
        "test_model(model, sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eed1157",
      "metadata": {
        "id": "9eed1157"
      },
      "source": [
        "## Using specified input sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f271137e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f271137e",
        "outputId": "4b96fc87-8c78-4f0c-bb11-3961dcabe7c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Temperature: 0.2\n",
            "Generating with seed: \"чтобы стать самым счастливым человеком, нужно лишь\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-b39c49399580>:4: RuntimeWarning: divide by zero encountered in log\n",
            "  preds = np.log(preds) / temperature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: \"чтобы стать самым счастливым человеком, нужно лишь в этом мире очень слово, ты не стали и самой только часть мы смысле.\n",
            "почему тебе просто любовь такой деньги в старости себе подайте с торого в чётно, вы и тебе не забой сильнее, не старости и равно настоящие начинается назад. не верить в сердце и подобно бы так рассказатье, чем счастливым.\n",
            "даже создано с уже не могу дыи слё не обера нужно ты не стались своим породителей своей себя.\n",
            "не пон\"\n",
            "\n",
            "* Temperature: 0.5\n",
            "Generating with seed: \"чтобы стать самым счастливым человеком, нужно лишь\"\n",
            "Generated text: \"чтобы стать самым счастливым человеком, нужно лишь за слово с делах, останет только сожидьны, старым в окрытваядется проивым дело с колоннает твойт, что с ужаеть себе в дет иметь сердце и вериться в основенно расная любовь — это понимаю, что были очень слова, он был мне поддемстрим и рассказать своими мы знаем сердце не обладаться себе, а вы не понимаешь, что важелать мир и возможно знаешь, что всё, как главное красиво иногда совершенно нет при\"\n",
            "\n",
            "* Temperature: 1.0\n",
            "Generating with seed: \"чтобы стать самым счастливым человеком, нужно лишь\"\n",
            "Generated text: \"чтобы стать самым счастливым человеком, нужно лишь только и что удоваламия взлость взрослат, дожгосте меня. хотело, что после руки... несторовым не последния нет. пусть застачь сказал, что сам мне самые в тома, ида не ленищем, но корять черодку. действительной человече, ненатою.\n",
            "спокойным. я если ненавистическом стряхом чустью считаться и радокой самому из косой, никогда не протятел не верекому!\n",
            "исторов. это тобы э чанчену и болит, это несбо\"\n",
            "\n",
            "* Temperature: 1.2\n",
            "Generating with seed: \"чтобы стать самым счастливым человеком, нужно лишь\"\n",
            "Generated text: \"чтобы стать самым счастливым человеком, нужно лишь все поксям ваш бы, пророествен поначарбую своим простлих убияться.  — чтобы вотроде женщина.\n",
            "если ты так жизомны опереф, некигданый куринечись назани. неправилое планежалое игруется чемо его хочет в крупым и рабочакобы, но ты тоже не болье же одно была и...\n",
            "цажное люди не слапогия чувствая самых людей ветаю правилопине, ко он-ида есть. пого их.\n",
            "всей малась с зи бы хотить радкрутся, можно после\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentence = 'Чтобы стать самым счастливым человеком, нужно лишь'.lower()\n",
        "test_model(model, sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DbHfmKRU736A",
      "metadata": {
        "id": "DbHfmKRU736A"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "87cee354",
      "metadata": {
        "id": "87cee354"
      },
      "outputs": [],
      "source": [
        "model_path = f'{drive_path}/russian_quotes_model_one_sixth_06_12_23.keras'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "qr_jcG3ltmqI",
      "metadata": {
        "id": "qr_jcG3ltmqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08adabb-022e-4b56-aa8c-2eb2a0b43fed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to path drive/MyDrive/russian_quotes_model_one_sixth_06_12_23.keras\n"
          ]
        }
      ],
      "source": [
        "model.save(model_path)\n",
        "\n",
        "print(f'Model saved to path {model_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd73b8b6",
      "metadata": {
        "id": "dd73b8b6"
      },
      "source": [
        "# Load & run model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "acc2bdad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-12-06T07:37:25.755613Z",
          "start_time": "2023-12-06T07:37:24.998558Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acc2bdad",
        "outputId": "7cd2dc05-8062-46f5-f832-0b0c3446c632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               135168    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 135)               17415     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 152583 (596.03 KB)\n",
            "Trainable params: 152583 (596.03 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "loaded_model = keras.models.load_model(model_path, compile = False)\n",
        "loaded_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "loaded_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8920d733",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8920d733",
        "outputId": "fd35e1ce-b5b3-4472-a8db-310538804272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quotes count: 11181\n",
            "Raw text length: 1671104\n",
            "Corpus length: 1671104\n",
            "Total chars: 135\n"
          ]
        }
      ],
      "source": [
        "file_path = f'{drive_path}/quotes_one_sixth_version.txt'\n",
        "f = open(file_path, 'r', encoding = 'utf-8')\n",
        "quotes = f.readlines()\n",
        "f.close()\n",
        "print(f'Quotes count: {len(quotes)}')\n",
        "\n",
        "raw_text = ''.join(quotes)\n",
        "print(f'Raw text length: {len(raw_text)}')\n",
        "\n",
        "processed_text = raw_text.lower()\n",
        "chars = sorted(list(set(processed_text)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "print(f'Corpus length: {len(processed_text)}')\n",
        "print(f'Total chars: {len(chars)}')\n",
        "\n",
        "maxlen = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "4e23b1aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e23b1aa",
        "outputId": "c6d201b0-8ef5-4a0d-8d26-9fd566717d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Temperature: 0.2\n",
            "Generating with seed: \"чтобы стать самым счастливым человеком, нужно быть\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-b39c49399580>:4: RuntimeWarning: divide by zero encountered in log\n",
            "  preds = np.log(preds) / temperature\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: \"чтобы стать самым счастливым человеком, нужно быть слова, которые разум чьём словы создает себе подобно предподовать жизнь — это нет на человека, ты всего уже не верит в своей жизнь — почему им на забой слега, которая стой, которые старетельности.\n",
            " — не станение.\n",
            "они совершенно нет природен, который истивная необычно на свои предстанице и всегда совершенно нет представляется в ней если не может быть страшно, в такая ты станет принять своим \"\n",
            "\n",
            "* Temperature: 0.5\n",
            "Generating with seed: \"чтобы стать самым счастливым человеком, нужно быть\"\n",
            "Generated text: \"чтобы стать самым счастливым человеком, нужно быть свете до плакать все лишаешься, ты того, окончасть — это может потом просспо истины в оставляем доброго тем, кто его человека становиться, который из носомнетной хородометривал себя — это не становится избежать тогда менят своими ленственные и не способ напытаются сердце и сердце и всегда ей не могут богатыми.\n",
            "направоданиями счастелся за произом менять не тобой, слова он смертным и привыкуюте\"\n",
            "\n",
            "* Temperature: 1.0\n",
            "Generating with seed: \"чтобы стать самым счастливым человеком, нужно быть\"\n",
            "Generated text: \"чтобы стать самым счастливым человеком, нужно быть вашевляешь те. — а всех «встречивая сдиволюдривки ложе с вам ляжий и даже важно, хотеля один исторого — людвин застранием загац, маналала: «тор, ни зачем подыбать его, томам. поднятые счастливая шоговпечении ненавлей.\n",
            "аспехимой строитично, всегда любовь, а он и врага для смерти». насторовом обгановать на судьст вопрезятный пронций сам глупые тываются себя благодара... я не нужно радо сопроща\"\n",
            "\n",
            "* Temperature: 1.2\n",
            "Generating with seed: \"чтобы стать самым счастливым человеком, нужно быть\"\n",
            "Generated text: \"чтобы стать самым счастливым человеком, нужно быть живый красиво — деречущим.\n",
            "я понятье, когда вся для реалущого рейстивы; и вять снавания: сездачь стества... мое оделое. отогда сумешься.\n",
            "что застанись вотное релит.\n",
            "у кручаем жизущким вядолет. смиранные и бердуевствий женщине все будет, же травают себя он моворостивля зо преупесным все занямение,  — сколько с делее? — бугу. значин: как застаневием и ожидека живощность таково), кто из-зро.\n",
            "след\"\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sentence = 'Чтобы стать самым счастливым человеком, нужно быть'.lower()\n",
        "test_model(model, sentence)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "384px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}